{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# IMPORT MODULES\nimport pandas as pd\nimport numpy as np\nimport os\nimport librosa\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport librosa.display\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\nfrom keras.regularizers import l2\nfrom keras.callbacks import EarlyStopping\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:25:25.958745Z","iopub.execute_input":"2023-10-15T12:25:25.959231Z","iopub.status.idle":"2023-10-15T12:25:25.966055Z","shell.execute_reply.started":"2023-10-15T12:25:25.959200Z","shell.execute_reply":"2023-10-15T12:25:25.964980Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"'''\n# Get the current directory of the script\nscript_dir = os.path.dirname(os.path.abspath(__file__))\n\n# Specify the relative paths to the dataset directories\ntess_dataset_relative_path = 'datasets/TESS'\ncremad_dataset_relative_path = 'datasets/CREMA-D/AudioWAV'\nravdess_dataset_relative_path = 'datasets/RAVDESS'\nsavee_dataset_relative_path = 'datasets/SAVEE'\n\n# Construct the absolute paths to the dataset directories\ntess_dataset_path = os.path.join(script_dir, tess_dataset_relative_path)\ncremad_dataset_path = os.path.join(script_dir, cremad_dataset_relative_path)\nravdess_dataset_path = os.path.join(script_dir, ravdess_dataset_relative_path)\nsavee_dataset_path = os.path.join(script_dir, savee_dataset_relative_path)\n'''\n\ncremad_dataset_path = '/kaggle/input/speech-emotion-recognition-en/Crema'\nravdess_dataset_path = '/kaggle/input/speech-emotion-recognition-en/Ravdess'\nsavee_dataset_path = '/kaggle/input/speech-emotion-recognition-en/Savee'\ntess_dataset_path = '/kaggle/input/speech-emotion-recognition-en/Tess'\n\n# Create the paths and labels lists\npaths = []\nlabels = []\n\n# LOAD THE TESS DATASET\nfor dirname, _, filenames in os.walk(tess_dataset_path):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        if label == 'ps':\n            label = 'surprise'\n        labels.append(label)\n    if len(paths) == 2800:\n        break\nprint('TESS dataset is loaded.')\n\n# Dictionary for mapping the CREMA-D dataset to the same labels as the TESS dataset.\ncremad_emotion_dict = {\n    \"ANG\": \"angry\",\n    \"DIS\": \"disgust\",\n    \"FEA\": \"fear\",\n    \"HAP\": \"happy\",\n    \"NEU\": \"neutral\",\n    \"SAD\": \"sad\"\n}\n\n# LOAD THE CREMA-D DATASET\nfor dirname, _, filenames in os.walk(cremad_dataset_path):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[2]\n        label = cremad_emotion_dict[label]\n        labels.append(label)\n    if len(paths) == 7442:\n        break\nprint('CREMA-D dataset is loaded.')\n\n# Dictionary for mapping the RAVDESS dataset to the same labels as the TESS dataset.\nravdess_emotion_dict = {\n    \"01\": \"neutral\",\n    \"02\": \"neutral\",  # originally \"calm\"\n    \"03\": \"happy\",\n    \"04\": \"sad\",\n    \"05\": \"angry\",\n    \"06\": \"fear\",\n    \"07\": \"disgust\",\n    \"08\": \"surprise\"\n}\n\n# LOAD THE RAVDESS DATASET\nfor dirname, _, filenames in os.walk(ravdess_dataset_path):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('-')[2]\n        label = ravdess_emotion_dict[label]\n        labels.append(label)\n    if len(paths) == 1440:\n        break\nprint('RAVDESS dataset is loaded.')\n\n# Dictionary for mapping the RAVDESS dataset to the same labels as the TESS dataset.\nsavee_emotion_dict = {\n    \"KL\": \"angry\",\n    \"JK\": \"happy\",\n    \"JE\": \"sad\",\n    \"DC\": \"neutral\"\n}\n\n# LOAD THE SAVEE DATASET\nfor dirname, _, filenames in os.walk(savee_dataset_path):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[0]\n        label = savee_emotion_dict[label]\n        labels.append(label)\n    if len(paths) == 480:\n        break\nprint('SAVEE dataset is loaded.')\n\nprint(len(paths))\nprint(len(labels))\n\n## Create a dataframe\ndf = pd.DataFrame()\ndf['speech'] = paths\ndf['label'] = labels\nprint(df.head())\n\nprint(df['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:25:25.969725Z","iopub.execute_input":"2023-10-15T12:25:25.970164Z","iopub.status.idle":"2023-10-15T12:25:33.036003Z","shell.execute_reply.started":"2023-10-15T12:25:25.970140Z","shell.execute_reply":"2023-10-15T12:25:33.034985Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"TESS dataset is loaded.\nCREMA-D dataset is loaded.\nRAVDESS dataset is loaded.\nSAVEE dataset is loaded.\n12162\n12162\n                                              speech label\n0  /kaggle/input/speech-emotion-recognition-en/Te...  fear\n1  /kaggle/input/speech-emotion-recognition-en/Te...  fear\n2  /kaggle/input/speech-emotion-recognition-en/Te...  fear\n3  /kaggle/input/speech-emotion-recognition-en/Te...  fear\n4  /kaggle/input/speech-emotion-recognition-en/Te...  fear\nlabel\nangry       1983\nsad         1983\nhappy       1983\nneutral     1895\nfear        1863\ndisgust     1863\nsurprise     592\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"## Feature Extraction\ndef extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc\n\nX_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))\n\nX = [x for x in X_mfcc]\nX = np.array(X)\nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:25:33.038182Z","iopub.execute_input":"2023-10-15T12:25:33.038815Z","iopub.status.idle":"2023-10-15T12:29:18.929340Z","shell.execute_reply.started":"2023-10-15T12:25:33.038781Z","shell.execute_reply":"2023-10-15T12:29:18.928199Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(12162, 40)\n","output_type":"stream"}]},{"cell_type":"code","source":"## Input Split\nX = np.expand_dims(X, -1)\nprint(X.shape)\n\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['label']])\ny = y.toarray()\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:29:18.934671Z","iopub.execute_input":"2023-10-15T12:29:18.935348Z","iopub.status.idle":"2023-10-15T12:29:18.962922Z","shell.execute_reply.started":"2023-10-15T12:29:18.935304Z","shell.execute_reply":"2023-10-15T12:29:18.958519Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(12162, 40, 1)\n(12162, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"## Create the LSTM Model\n\nmodel = Sequential([\n    LSTM(512, return_sequences=True, input_shape=(40,1)),\n    Dropout(0.3),  # Reduced dropout rate\n    LSTM(256, return_sequences=True),\n    Dropout(0.3),  # Reduced dropout rate\n    LSTM(128, return_sequences=False),\n    Dropout(0.2),  # Reduced dropout rate\n    Dense(256, activation='relu'),\n    Dropout(0.2),  # Reduced dropout rate\n    Dense(128, activation='relu'),\n    Dropout(0.1),  # Reduced dropout rate\n    Dense(7, activation='softmax')\n])\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:10:07.711051Z","iopub.execute_input":"2023-10-15T13:10:07.711391Z","iopub.status.idle":"2023-10-15T13:10:12.664320Z","shell.execute_reply.started":"2023-10-15T13:10:07.711361Z","shell.execute_reply":"2023-10-15T13:10:12.663558Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Model: \"sequential_17\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm_49 (LSTM)              (None, 40, 512)           1052672   \n                                                                 \n dropout_83 (Dropout)        (None, 40, 512)           0         \n                                                                 \n lstm_50 (LSTM)              (None, 40, 256)           787456    \n                                                                 \n dropout_84 (Dropout)        (None, 40, 256)           0         \n                                                                 \n lstm_51 (LSTM)              (None, 128)               197120    \n                                                                 \n dropout_85 (Dropout)        (None, 128)               0         \n                                                                 \n dense_51 (Dense)            (None, 256)               33024     \n                                                                 \n dropout_86 (Dropout)        (None, 256)               0         \n                                                                 \n dense_52 (Dense)            (None, 128)               32896     \n                                                                 \n dropout_87 (Dropout)        (None, 128)               0         \n                                                                 \n dense_53 (Dense)            (None, 7)                 903       \n                                                                 \n=================================================================\nTotal params: 2,104,071\nTrainable params: 2,104,071\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"## Train the model\nearly_stop = EarlyStopping(monitor='val_loss', patience=20)  # Early stopping\n\nhistory = model.fit(X, y, validation_split=0.2, epochs=100, batch_size=64, callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:10:15.436091Z","iopub.execute_input":"2023-10-15T13:10:15.437068Z","iopub.status.idle":"2023-10-15T13:11:30.020234Z","shell.execute_reply.started":"2023-10-15T13:10:15.437036Z","shell.execute_reply":"2023-10-15T13:11:30.019126Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Epoch 1/100\n153/153 [==============================] - 10s 29ms/step - loss: 1.4818 - accuracy: 0.3733 - val_loss: 2.6308 - val_accuracy: 0.2343\nEpoch 2/100\n153/153 [==============================] - 3s 21ms/step - loss: 1.3878 - accuracy: 0.4268 - val_loss: 2.4916 - val_accuracy: 0.2236\nEpoch 3/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.2481 - accuracy: 0.4781 - val_loss: 2.9303 - val_accuracy: 0.2088\nEpoch 4/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.2079 - accuracy: 0.4960 - val_loss: 3.0217 - val_accuracy: 0.2380\nEpoch 5/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.1526 - accuracy: 0.5203 - val_loss: 3.1358 - val_accuracy: 0.2400\nEpoch 6/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.1298 - accuracy: 0.5276 - val_loss: 3.0155 - val_accuracy: 0.2491\nEpoch 7/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.1079 - accuracy: 0.5420 - val_loss: 2.9989 - val_accuracy: 0.2219\nEpoch 8/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.1155 - accuracy: 0.5370 - val_loss: 3.2972 - val_accuracy: 0.2067\nEpoch 9/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.1622 - accuracy: 0.5126 - val_loss: 3.5624 - val_accuracy: 0.2092\nEpoch 10/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.1043 - accuracy: 0.5444 - val_loss: 3.4543 - val_accuracy: 0.2244\nEpoch 11/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.0693 - accuracy: 0.5609 - val_loss: 3.4839 - val_accuracy: 0.2224\nEpoch 12/100\n153/153 [==============================] - 3s 21ms/step - loss: 1.0841 - accuracy: 0.5628 - val_loss: 3.5544 - val_accuracy: 0.2018\nEpoch 13/100\n153/153 [==============================] - 3s 21ms/step - loss: 1.0777 - accuracy: 0.5558 - val_loss: 4.1990 - val_accuracy: 0.2117\nEpoch 14/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.0393 - accuracy: 0.5747 - val_loss: 3.7407 - val_accuracy: 0.2035\nEpoch 15/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.0721 - accuracy: 0.5608 - val_loss: 4.0424 - val_accuracy: 0.2207\nEpoch 16/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.0219 - accuracy: 0.5848 - val_loss: 3.7919 - val_accuracy: 0.2281\nEpoch 17/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.0129 - accuracy: 0.5871 - val_loss: 4.1135 - val_accuracy: 0.2265\nEpoch 18/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.0048 - accuracy: 0.5874 - val_loss: 4.0439 - val_accuracy: 0.2339\nEpoch 19/100\n153/153 [==============================] - 3s 20ms/step - loss: 1.0115 - accuracy: 0.5937 - val_loss: 4.5402 - val_accuracy: 0.2174\nEpoch 20/100\n153/153 [==============================] - 3s 20ms/step - loss: 0.9956 - accuracy: 0.6007 - val_loss: 4.2919 - val_accuracy: 0.2219\nEpoch 21/100\n153/153 [==============================] - 3s 20ms/step - loss: 0.9829 - accuracy: 0.6009 - val_loss: 4.5815 - val_accuracy: 0.2326\nEpoch 22/100\n153/153 [==============================] - 3s 20ms/step - loss: 0.9866 - accuracy: 0.6099 - val_loss: 4.2727 - val_accuracy: 0.2478\n","output_type":"stream"}]},{"cell_type":"code","source":"## Result plotting\n\n# Accuracy\nepochs = list(range(len(history.history['accuracy'])))\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, label='train accuracy')\nplt.plot(epochs, val_acc, label='val accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()\n\n# Loss\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs, loss, label='train loss')\nplt.plot(epochs, val_loss, label='val loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:03:47.084467Z","iopub.status.idle":"2023-10-15T13:03:47.085157Z","shell.execute_reply.started":"2023-10-15T13:03:47.084925Z","shell.execute_reply":"2023-10-15T13:03:47.084950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_output2.keras')  # The file needs to end with the .keras extension","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:50:05.720176Z","iopub.execute_input":"2023-10-15T12:50:05.720560Z","iopub.status.idle":"2023-10-15T12:50:05.811223Z","shell.execute_reply.started":"2023-10-15T12:50:05.720532Z","shell.execute_reply":"2023-10-15T12:50:05.810173Z"},"trusted":true},"execution_count":41,"outputs":[]}]}